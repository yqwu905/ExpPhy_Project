\documentclass{article}
\usepackage[dvipsnames, svgnames, x11names]{xcolor}
\usepackage{ctex}
\usepackage{cite}
\usepackage{siunitx}
\usepackage{enumerate}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{physics}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{hyperref}
\usepackage[most]{tcolorbox}
\usepackage{subfigure}
\usepackage{float}
\usepackage{amssymb}

\numberwithin{equation}{subsection}

\lstset{
    basicstyle          =   \sffamily,          % 基本代码风格
    keywordstyle        =   \bfseries,          % 关键字风格
    commentstyle        =   \rmfamily\itshape,  % 注释的风格，斜体
    stringstyle         =   \ttfamily,  % 字符串风格
    flexiblecolumns,                % 别问为什么，加上这个
    numbers             =   left,   % 行号
    showspaces          =   false,  % 是否显示空格，显示了有点乱，所以不现实了
    numberstyle         =   \zihao{-5}\ttfamily,    % 行号的样式，小五号，tt等宽字体
    showstringspaces    =   false,
    captionpos          =   t,      % 这段代码的名字所呈现的位置，t指的是top上面
    frame               =   lrtb,   % 显示边框
}

\lstdefinestyle{Python}{
   language        =   Python, % 语言选Python
    basicstyle      =   \zihao{-5}\ttfamily,
    numberstyle     =   \zihao{-5}\ttfamily,
    keywordstyle    =   \color{blue},
    keywordstyle    =   [2] \color{teal},
    stringstyle     =   \color{magenta},
    commentstyle    =   \color{red}\ttfamily,
    breaklines      =   true,   % 自动换行，建议不要写太长的行
    columns         =   fixed,  % 如果不加这一句，字间距就不固定，很丑，必须加
    basewidth       =   0.5em,
}


\begin{document}
\begin{titlepage}
  %\clearpage
  \thispagestyle{empty}
  \centering
  \vspace{1cm}

  % Titles
  % Information about the University
  {\
	  \textsc{武汉大学 2021-2022学年 综合物理实验5}
  }
  \vspace{1.5 cm}

  \rule{\linewidth}{2mm} \\[0.8cm]
  { \LARGE \sc 基于神经网络的风格迁移}\\[0.55cm]
  \rule{\linewidth}{0.6mm} \\[2.4cm]

  \hspace{1cm}
  \begin{tabular}{l p{6cm}}
          \textbf{Name} & \textbf{吴远清}\\[10pt]
          \textbf{Department} & 弘毅学堂 \\[10pt]
          \textbf{Date} & \today \\
  \end{tabular}

  %\vfill
  \vspace{2cm}
  % Light logo and Dark logo
\begin{center}
\includegraphics[width=4.5cm]{image/school_tag.png}
\end{center}
  \begin{center}
\includegraphics[width=4.5cm]{image/school_name.jpg}
\end{center}
  \vspace{0.5cm}
  %\pagebreak
  \global\let\newpagegood\newpage
\global\let\newpage\relax
\end{titlepage}
\global\let\newpage\newpagegood
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% Text body starts here!
%\clearpage
%\mainmatter
\setcounter{page}{1}

    % \maketitle
    % \centerline{\includegraphics[width=4.5cm]{image/school_tag.png}}
    \clearpage
    \tableofcontents
    \clearpage
	\section{简介}
	图像风格迁移是指对于两张给定的图片:
	一张内容图片(c)和一张风格图片(s),
	我们训练一个神经网络将c以s的'风格'重绘.\\
	目前有多种图像风格迁移的实现方式,
	例如可以通过基于生成对抗网络(Generative Adversarial Net, GAN)来实现,
	也可以通过传统的卷积神经网络(Convolutional Neural Network, CNN),
	最近的研究成果也有利用较新的Transformer模型来实现图像风格迁移的.\\
	在本实验报告中, 我将介绍基于CNN实现图像风格迁移的理论和技术细节,
	并给出一个基于PyTorch的实现, 展示一些在不同的内容图片与风格图片之间得到的结果,
	最后讨论一下模型中的参数设置与存在的一些问题, 并进行总结.

	\section{理论}
	利用CNN实现图像风格迁移的主要思路是, 输入{\bf 内容图像c}和{\bf 风格图像s}, 为了将s的风格迁移到c上, 我们需要分别提取出内容图像和风格图像的特征图,
	之后生成一个随机噪声图片x, 分别计算其内容特征图和风格特征图, 计算出x的特征图与c和s的特征图的损失函数, 并调整图像x, 使得x的风格特征图接近于s, 而x
	的内容特征图接近于c.\\
	\subsection{网络结构}
	在Gatys等人的论文中, 他们使用了vgg19作为基本框架, 但对于PyTorch来说, vgg19的实现不够稳定, 因此我们使用vgg16来作为基本网络结构.\\
	
	\subsection{损失函数}
	\subsubsection{内容损失函数}
	内容损失函数定义为随机噪声图像x和内容图像在内容特征上的欧氏距离:
	\begin{equation}
		L_{content}({\bf p}, {\bf x}, l) = \frac{1}{2} \sum_{i,j}\left(F^{l}_{i,j}-P^{l}_{i,j}\right)^{2}
	\end{equation}
	其中, $l$ 表示第$l$ 个网络层, $P^{l}_{ij}$表示内容图片$p$ 在第$l$ 个网络层中第$i$ 个特征图上位置$j$ 处的特征值, $F^{l}_{ij}$ 表示生成图片$x$ 在第$l$ 个网络层中第$i$ 个特征图上位置$j$ 处的特征值.\\
	对于反向传播过程, 内容损失函数对$F^{l}_{ij}$的偏导为:
	 \begin{equation}
		 \frac{\partial L_{content}}{\partial F^{l}_{ij}} = 
		 \left\{
			 \begin{aligned}
				&(F^{l}-P^{l})_{ij}\quad & F^{l}_{ij}>0 \\
				&0&F^{l}_{ij}\leq 0
			 \end{aligned}
		\right.
	\end{equation}
	具体的Python实现参见附录代码\ref{ContentLossClass}.

	\subsubsection{风格损失函数}
	风格损失函数使用五层卷积的特征来计算风格损失，图像的风格特征定义为第 $l$ 层中的第$i$ 个和第$j$ 个特征图的内积:
	\begin{equation}
		G^{l}_{ij} = \sum_{k}F^{l}_{ik}F^{l}_{jk}
	\end{equation}
	这一内积构成了一个被称为Gram Matrix的对称矩阵.\\
	相应的, 第$l$ 层的风格损失定义为两图片的风格特征$G^{l}_{ij}$ 和$A^{l}_{ij}$ 之间的欧氏距离:
	\begin{equation}
		E_l = \frac{1}{4N^{2}_{l}M^{2}_{l}} \sum_{i,j}(G^{l}_{ij}-A^{l}_{ij})^{2}
	\end{equation}
	最后, 整体的风格损失函数定义为各层的风格损失的加权求和:
	\begin{equation}
		{\bf L}_{style} ({\bf a}, {\bf x}) = \sum_{l} w_{l}E_{l}
	\end{equation}
	其中, $w_{l}$ 为第$l$ 层的权重, 为提前给定的经验参数.\\
	相应的, 风格损失对于$F^{l}_{ij}$ 的偏导为:
	 \begin{equation}
		 \frac{\partial E_{l}}{\partial F^{l}_{ij}} = 
		 \left\{
			 \begin{aligned}
				 &\frac{1}{N^{2}_{l}M^{2}_{l}}((F^{l})^{T}(G^{l}-A^{l}))_{ji},\quad & F^{l}_{ij}>0\\
				 &0&F^{l}_{ij}\leq 0
			 \end{aligned}
		\right.
	\end{equation}
	计算Gram矩阵,也就是图像风格特征的Python实现见\ref{GramMatrixClass}, 而风格损失函数的Python实现参见附录代码\ref{StyleLossClass}.

\appendix
\section{Appendix}

\begin{lstlisting}[style=Python, caption={\bf ContentLoss类}, label={ContentLossClass}]
class ContentLoss(torch.nn.Module):
    """Content Loss class"""
    def __init__(self, weight, target):
        """Init some settings
        :weight: weight matrix
        :target: Desire output
        """
        torch.nn.Module.__init__(self)
        self._weight = weight
        self._target = target.detach()*self._weight
        self.loss_fn = torch.nn.MSELoss()

    def forward(self, input):
        """Forward method for Content Loss Layer
        :input: input matrix
        :returns: output matrix
        """
        self.loss = self.loss_fn(input*self._weight, self._target)
        self.output = input
        return self.output

    def backward(self):
        """Backward method for Content Loss Layer
        :returns: TODO
        """
        self.loss.backward(retain_graph=True)
        return self.loss
\end{lstlisting}

\begin{lstlisting}[style=Python, caption={\bf GramMatrix类}, label={GramMatrixClass}]
class GramMatrix(torch.nn.Module):
    """Gram Matrix Class"""
    def __init__(self):
        """Do nothing """
        torch.nn.Module.__init__(self)

    def forward(self, input):
        """Forward method for gram matrix
        :input: matrix
        :returns: TODO
        """
        a, b, c, d = input.size()
        feature = input.view(a*b, c*d)
        gram = torch.mm(feature, feature.t())
        return gram.div(a*b*c*d)
\end{lstlisting}

\begin{lstlisting}[style=Python, caption={\bf StyleLoss类}, label={StyleLossClass}]
class StyleLoss(torch.nn.Module):
    """Style Loss Class"""
    def __init__(self, weight, target):
        """TODO: to be defined.
        :weight: weight matrix
        :target: Desire output
        """
        torch.nn.Module.__init__(self)
        self._weight = weight
        self._target = target.detach()*self._weight
        self._loss_fn = torch.nn.MSELoss()
        self._gram = GramMatrix()

    def forward(self, input):
        """Forward mehod for Style Loss
        :input: input matrix
        :returns: output matrix
        """
        self.output = input.clone()
        self.G = self._gram(input)
        self.G.mul_(self._weight)
        self.loss = self._loss_fn(self.G, self._target)
        return self.output

    def backward(self):
        """Backward method for Style loss
        :returns: Loss matrix
        """
        self.loss.backward(retain_graph=True)
        return self.loss
\end{lstlisting}

	\bibliographystyle{unsrt}
	\bibliography{reference}
\end{document}
